# Generic crawler for BlogSearch

// Asciidoc references
// Documentation: https://asciidoctor.org/docs/user-manual/
// Quick reference: https://asciidoctor.org/docs/asciidoc-syntax-quick-reference/
// Asciidoc vs Markdown: https://asciidoctor.org/docs/user-manual/#comparison-by-example
// GitHub Flavored Asciidoc (GFA): https://gist.github.com/dcode/0cfbf2699a1fe9b46ff04c41721dda74

:project-version: 0.0.3

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

NOTE: This is a part of link:../[BlogSearch project]. If you would like to know the overall concept, go to link:../[the parent directory].

## 1. Building a search index file

### The easiest way
[source,bash]
npx blogsearch-crawler

### The formal way
[source,bash]
npm install blogsearch-crawler

[source,javascript]
----
npm run blogsearch-crawler

# or

yarn run blogsearch-cralwer
----

### Configuration

.blogsearch.config.js
[source,javascript,options="nowrap"]
----
module.exports = {
  type: 'simple', // required <1>
  output: './my_blog_index.db.wasm', // required <2>
  entries: [ // required <3>
    './reactjs.org/public/docs/**/*.html'
  ],
  fields: { // required <4>
    title: {
      // The value can be a CSS selector.
      parser: 'article > header', // <5>
    },
    body: {
      // Set false if you want to reduce the size of the database.
      hasContent: true,
      // It can be a function as well.
      parser: (entry, page) => {
        // Use puppeteer page object.
        // It's okay to return a promise.
        return page.$eval('article > div > div:first-child', el => el.textContent);
      }
    },
    url: {
      // By setting this false the search engine won't index the URL.
      indexed: false,
      parser: (entry, page) => {
        // entry is a string of the path being parsed.
        return entry.replace('./reactjs.org/public', 'https://reactjs.org');
      },
    },
    categories: {
      // This is disabled because the target website doesn't have categories.
      enabled: false,
      // This is a dummy parser. This is unused because the field is disabled.
      parser: () => 'categories-1, categories-2',
    },
    tags: {
      // This is disabled because the target website doesn't have tags.
      enabled: false,
      // This is a dummy parser. This is unused because the field is disabled.
      parser: () => 'tags-1, tags-2',
    },
  }
};
----
<1> This must be 'simple'.
<2> output
Generated blogsearch database file.
Note that you might not want to use .db instead of .wasm (or .db.wasm).
Setting improper file extension may lead file format corruption. .wasm.db is recommended. compressed by web servers.
Make sure that web servers compress the file extension you choose.
(e.g. Content-Encoding: gzip included in the response) 
<3> List of entries to parse. The crawler uses glob pattern internally.
How to use glob: https://github.com/isaacs/node-glob
<4> Field configurations of the database.
<5> Selector

.There are 5 fields you need to configure:
* title
* body
* url
* categories
* tags

.Options for a field
* indexed: boolean
**  Set if the field is indexed or not.
* hasContent: boolean
**  When disabled (set as false) the content of the field won't
    appear in the search result. The data still will be indexed
    even if hasContent is disabled.
    Recommended to be disabled to reduce the size of the output size.
* parser:
**  parser configuration. parser can have the following types:  
***   string
****    This is considered as a CSS selector.
*** function (entry, page: puppeteer::page) => string | Promise<string>
****    This is a generic parser function when a CSS selector is not available.
*** false
****    This can be use if you don't want to parse the field.


## 2. Enabling the search engine in the webpage

You need to enable the search engine in the web page. Go to link:../blogsearch[blogsearch Engine].

Again, if you would like to understand the concept of BlogSearch, go to link:../[the parent directory].
