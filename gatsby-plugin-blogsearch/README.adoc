# Gatsby plugin for BlogSearch

// Asciidoc references
// Documentation: https://asciidoctor.org/docs/user-manual/
// Quick reference: https://asciidoctor.org/docs/asciidoc-syntax-quick-reference/
// Asciidoc vs Markdown: https://asciidoctor.org/docs/user-manual/#comparison-by-example
// GitHub Flavored Asciidoc (GFA): https://gist.github.com/dcode/0cfbf2699a1fe9b46ff04c41721dda74

:project-version: 0.0.3
:rootdir: https://github.com/kbumsik/blogsearch

ifdef::env-github[]
// Emoji
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
// URL
:imagesdir: https://gist.githubusercontent.com/path/to/gist/revision/dir/with/all/images
endif::[]

CAUTION: This is a part of link:{rootdir}[BlogSearch project]. If you would like to know the overall concept, go to link:{rootdir}[the parent directory].

## 1. Building a search index file

### Installation

[source,shell]
npm install gatsby-plugin-blogsearch

### Configuration

.gatsby.config.js
[source,javascript,options="nowrap"]
----
module.exports = {
  ...
  other Gatsby options
  ...

  plugins: [
    {
      resolve: 'gatsby-plugin-blogsearch',
      options: {
        // Generated blogsearch database file.
        output: 'reactjs.org.gatsby-example.db.wasm',
        // fields configurations
        fields: {
          title: {
            enabled: true,
            indexed: true,
            hasContent: true,
          },
          body: {
            enabled: true,
            indexed: true,
            hasContent: true,
          },
          url: {
            enabled: true,
            indexed: true,
            hasContent: true,
          },
          categories: {
            enabled: true,
            indexed: true,
            hasContent: true,
          },
          tags: {
            enabled: true,
            indexed: true,
            hasContent: true,
          },
        },
        // GraphQL query used to fetch all data for the search index. This is
        // required.
        query: `
        {
          allMarkdownRemark {
            edges {
              node {
                fields {
                  slug
                }
                frontmatter {
                  title
                }
                rawMarkdownBody
                # excerpt
                # html
              }
            }
          }
        }
        `,
        // Function used to map the result from the GraphQL query. This should
        // return an array of items to index in the form of flat objects
        // containing properties to index. The objects must contain the `ref`
        // field above (default: 'id'). This is required.
        normalizer: ({ data }) =>
          data.allMarkdownRemark.edges.map(({ node }, siteUrl) => {
            return {
              title: node.frontmatter.title,
              body: node.rawMarkdownBody
                      .replace(/[#`\[\]]+/g, '')
                      .replace(/\(.*\)/g, '')
                      .replace(/\s+/g, ' '),
              url: siteUrl + node.fields.slug,
              categories: (() => {
                const slug = node.fields.slug;
                return slug ? slug.substring(0, slug.indexOf('/')) : '';
              })(),
              tags: '',
            };
          }),
      },
    },
    ...
    Other Gatsby plugin options
    ...
  ],
  ...
  Rest of Gatsby options
  ...
};
----
<1> This must be 'simple'.
<2> output
Generated blogsearch database file.
Note that you might not want to use .db instead of .wasm (or .db.wasm).
Setting improper file extension may lead file format corruption. .wasm.db is recommended. compressed by web servers.
Make sure that web servers compress the file extension you choose.
(e.g. Content-Encoding: gzip included in the response) 
<3> List of entries to parse. The crawler uses glob pattern internally.
How to use glob: https://github.com/isaacs/node-glob
<4> Field configurations of the database.
<5> Selector

.There are 5 fields you need to configure:
* title
* body
* url
* categories
* tags

.Options for a field
* indexed: boolean
**  Set if the field is indexed or not.
* hasContent: boolean
**  When disabled (set as false) the content of the field won't
    appear in the search result. The data still will be indexed
    even if hasContent is disabled.
    Recommended to be disabled to reduce the size of the output size.
* parser:
**  parser configuration. parser can have the following types:  
***   string
****    This is considered as a CSS selector.
*** function (entry, page: puppeteer::page) => string | Promise<string>
****    This is a generic parser function when a CSS selector is not available.
*** false
****    This can be use if you don't want to parse the field.


## 2. Enabling the search engine in the webpage

You need to enable the search engine in the web page. Go to link:../blogsearch[blogsearch Engine].

Again, if you would like to understand the concept of BlogSearch, go to link:../[the parent directory].
